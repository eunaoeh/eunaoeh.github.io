<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-08-21T20:38:12+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Eunaoeh’s Dev Blog</title><author><name>Eunjin</name></author><entry><title type="html">NAVER AI Tech Boostcamp Week1 회고록</title><link href="http://localhost:4000/naver%20ai%20tech%20boostcamp/week1/" rel="alternate" type="text/html" title="NAVER AI Tech Boostcamp Week1 회고록" /><published>2021-08-21T00:00:00+09:00</published><updated>2021-08-21T00:00:00+09:00</updated><id>http://localhost:4000/naver%20ai%20tech%20boostcamp/week1</id><content type="html" xml:base="http://localhost:4000/naver%20ai%20tech%20boostcamp/week1/">&lt;h2 id=&quot;이번주에-한-일&quot;&gt;이번주에 한 일&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;최성준 교수님의 Python, Numpy, Pandas 강의를 들었다.&lt;/li&gt;
  &lt;li&gt;임성빈 교수님의 기초 확률통계론, 수학, 경사하강법, 기초 RNN, 기초 CNN 강의를 들었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;좋았던-점&quot;&gt;좋았던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;AI에 관한 경사하강법에 대해 확실하게 이해하고 넘어갈 수 있었다.&lt;/li&gt;
  &lt;li&gt;확률통계론은 아직도 어렵지만 예전보다는 많이 익숙해졌다. 임성빈 교수님께서 수학은 익숙해지고 꾸준히 하는 것이 중요하다고 하셨다. 교수님께서는 아직도 매일 수학공부를 하신다고 하셨다..&lt;/li&gt;
  &lt;li&gt;임성빈 교수님의 마스터 클래스를 듣고 대학원에 대한 생각을 정리할 수 있어서 좋았다. 생소한 분야는 가는 것이 거의 필수지만, 그게 아니라면 꼭 필요한 것은 아니라고 하셨다.&lt;/li&gt;
  &lt;li&gt;멘토링 시간 때, 그 동안 궁금했던 것(포트폴리오나 진로 등)에 대한 궁금증을 해결할 수 있었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;아쉬웠던-점&quot;&gt;아쉬웠던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;첫 주차에 Precourse + 강의여서 그런지 너무 정신없게 지낸 것 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;개선시도할-점&quot;&gt;개선/시도할 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;앞으로도 강의가 이렇게 많으면 부지런하게 공부하는 것이 중요할 것 같다.&lt;/li&gt;
  &lt;li&gt;시간관리 잘 하고 다른 공부도 꾸준히 하자!&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Eunjin</name></author><category term="NAVER AI Tech Boostcamp" /><category term="NAVER AI Tech Boostcamp" /><category term="AI" /><category term="회고록" /><summary type="html">이번주에 한 일 최성준 교수님의 Python, Numpy, Pandas 강의를 들었다. 임성빈 교수님의 기초 확률통계론, 수학, 경사하강법, 기초 RNN, 기초 CNN 강의를 들었다.</summary></entry><entry><title type="html">NAVER AI Tech Boostcamp Week2 회고록</title><link href="http://localhost:4000/naver%20ai%20tech%20boostcamp/week2/" rel="alternate" type="text/html" title="NAVER AI Tech Boostcamp Week2 회고록" /><published>2021-08-21T00:00:00+09:00</published><updated>2021-08-21T00:00:00+09:00</updated><id>http://localhost:4000/naver%20ai%20tech%20boostcamp/week2</id><content type="html" xml:base="http://localhost:4000/naver%20ai%20tech%20boostcamp/week2/">&lt;h2 id=&quot;이번주에-한-일&quot;&gt;이번주에 한 일&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;최성준 교수님의 Deep Learning Basics 강의를 들었다.&lt;/li&gt;
  &lt;li&gt;이고잉님의 Github 강의를 들었다.&lt;/li&gt;
  &lt;li&gt;최성준 교수님의 마스터 클래스 강의를 들었다.&lt;/li&gt;
  &lt;li&gt;블로그를 시작했다.&lt;/li&gt;
  &lt;li&gt;피어들과 알고리즘 스터디를 진행했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;좋았던-점&quot;&gt;좋았던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;사실 귀찮아서 터미널 꾸미기나 컴퓨터정리를 안 하고 있었는데 이번 기회에 꾸몄더니 기분이 좋아졌다. 이거 하는데도 삽질을 많이 해서 나중에 시간이 되면 올리도록 하겠다.&lt;/li&gt;
  &lt;li&gt;드디어 github 블로그를 만들었다!! 블로그도 만드는데 아주아주아주 많은 삽질을 하였다. 대체 왜 내 노트북에는 설치가 안 되는지….고생했지만 이제 끝!&lt;/li&gt;
  &lt;li&gt;블로그 구조도 원래는 상단 카테고리 바에 모든 걸 보여주고 싶어서 그렇게 만들었는데 막상 사이드바까지 만들고 나니까 복잡한 것 같아서 무난한 기본 세팅으로 변경했다.&lt;/li&gt;
  &lt;li&gt;이고잉님의 Git 강의를 들으면서 Git의 기본적인 기능에 대해 이해할 수 있었고, vscode gui로 쉽게 git commit하는 법까지 배울 수 있었다. vscode 터미널로만 git을 사용했는데 gui 사용하는 방법도 있다는 것을 알았지만, git graph 보는 것 말고는 잘 안 쓸 것 같다..&lt;/li&gt;
  &lt;li&gt;수강신청도 사실 잡을 건 많이 없었지만 올클해서 기분이 좋다.&lt;/li&gt;
  &lt;li&gt;AI 부스트캠프 온보딩키트를 드디어 받았다!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;아쉬웠던-점&quot;&gt;아쉬웠던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;RNN, GAN에 대한 아이디어에 대한 감은 잡았지만, 자세한 수식까지 이해하는건 좀 힘이 들었다. 사실 다 이해 못 했지만, 주말에 시간 나면 공부해야겠다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;개선시도할-점&quot;&gt;개선/시도할 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;블로그에 꾸준히 글 올리자!&lt;/li&gt;
  &lt;li&gt;알고리즘도 꾸준히 하자!&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Eunjin</name></author><category term="NAVER AI Tech Boostcamp" /><category term="NAVER AI Tech Boostcamp" /><category term="AI" /><category term="회고록" /><summary type="html">이번주에 한 일 최성준 교수님의 Deep Learning Basics 강의를 들었다. 이고잉님의 Github 강의를 들었다. 최성준 교수님의 마스터 클래스 강의를 들었다. 블로그를 시작했다. 피어들과 알고리즘 스터디를 진행했다.</summary></entry><entry><title type="html">NAVER AI Tech Boostcamp Week3 회고록</title><link href="http://localhost:4000/naver%20ai%20tech%20boostcamp/week3/" rel="alternate" type="text/html" title="NAVER AI Tech Boostcamp Week3 회고록" /><published>2021-08-21T00:00:00+09:00</published><updated>2021-08-21T00:00:00+09:00</updated><id>http://localhost:4000/naver%20ai%20tech%20boostcamp/week3</id><content type="html" xml:base="http://localhost:4000/naver%20ai%20tech%20boostcamp/week3/">&lt;h2 id=&quot;이번주에-한-일&quot;&gt;이번주에 한 일&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;이번주에는 Pytorch에 대한 강의를 들었다. 인턴을 하면서 Pytorch를 대충 사용할 수 있다고 생각했지만 몰랐던 부분, 잊고 있었던 부분을 리마인드 할 수 있었다.&lt;/li&gt;
  &lt;li&gt;과제 마감에만 집중을 하니 그냥 넘긴 부분도 있어서 다시 복습하고 블로그에 정리해야할 것 같다.&lt;/li&gt;
  &lt;li&gt;부스트캠프를 하느라 알고리즘, 개인공부, 블로그를 많이 못 했다.&lt;/li&gt;
  &lt;li&gt;안수빈님의 데이터 시각화 강의도 들었다.&lt;/li&gt;
  &lt;li&gt;라이엇 게임즈 유석문CTO님의 ‘개발자로 산다는것’, ‘Unit Test’ 강의를 들었다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;좋았던-점&quot;&gt;좋았던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;과제에서 Pytorch에 대한 Documentation처럼 자세하게 정리를 해주셔서 나중에도 보고 공부하면 많은 도움이 될 것 같다.&lt;/li&gt;
  &lt;li&gt;기본 Documentation 뿐만 아니라 Ray Tune, Multi-GPU 등에 대해서도 간단하게 설명을 해주셔서 많은 도움이 되었다.&lt;/li&gt;
  &lt;li&gt;그 동안 Pytorch, Detectron2(CV 프레임워크)처럼 Documentation의 함수를 뜯어보면서 공부를 했었는데 수업에서도 그렇게 하는 게 좋다고 말씀해주셔서 방향을 잘 잡고 공부했구나라는 생각이 들었다.&lt;/li&gt;
  &lt;li&gt;최성철 교수님의 마스터세션을 듣고, 무엇을 공부하면 될지 조금 더 확신이 생긴 것 같다.&lt;/li&gt;
  &lt;li&gt;혼자서 matplotlib을 공부할 때는 내가 만든 시각화가 정말 안 예쁘다고 생각했는데 어떻게 해야 에쁘게 그릴 수 있고, 내가 원하는 정보를 잘 전달할 수 있는지 안수빈님의 강의를 통해서 배울 수 있어서 너무 좋았다. Pytorch를 보다가 데이터 시각화 강의를 들으면 힐링하는 것 같아 마음이 편했다.&lt;/li&gt;
  &lt;li&gt;Transformer에 관심이 있어 Vision Transformer 논문을 읽어봐야지라고 인턴 때 생각했는데, 드디어 읽어볼 수 있었다. 블로그에 정리까지 완료!&lt;/li&gt;
  &lt;li&gt;SDS 알고리즘 강의 수료증이 코로나 때문에 돌고 돌아서 3주만에 왔다!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;아쉬웠던-점&quot;&gt;아쉬웠던 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;다른 개인 공부(CS, 알고리즘)를 할 시간이 없어서 아쉬웠다.&lt;/li&gt;
  &lt;li&gt;MLOps도 공부해야지라고 생각했는데 막상 시간이 잘 안 나는 것 같다. 괜히 한다했다가 개강하고 나면 시간이 아예 없을까봐 걱정된다.&lt;/li&gt;
  &lt;li&gt;Pytorch를 사용해서 직접 모델을 End-to-End로 구현하고 싶은데 수업정리, 과제마감을 하다보면 지쳐서 하기 힘들었다.&lt;/li&gt;
  &lt;li&gt;Pytorch도 어느정도 사용할 줄 알지만, 과제하는데만 집중해서 정리를 못 했다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eunaoeh.github.io/paper%20review/cv/ViT/&quot;&gt;Vision Transformer&lt;/a&gt; 논문 정리를 하긴 했지만 아직 논문을 100% 소화하기에는 부족한 부분도 많고, 핑계지만 시간도 부족해서 제대로 못 해서 아쉬운 부분이 많다. 논문 정리도 하다보면 점점 나아질 것이라고 생각한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;개선시도할-점&quot;&gt;개선/시도할 점&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;코어타임에 집중해서 끝내고 저녁시간은 내 자유시간으로 사용하자.&lt;/li&gt;
  &lt;li&gt;이제 곧 하반기 공채시즌인데 이를 준비하려면 CS, 알고리즘 공부를 열심히 해야할 것 같다.&lt;/li&gt;
  &lt;li&gt;MLOps도 공부하고 싶은데, MLOps가 결국에는 System Pipeline이라는 것이니까 먼저 데이터베이스, 운영체제, 네트워크부터 잘 알아야 할 것 같다. 일단 CS 정리를 한 번 하고, MLOps 강의를 듣던 공부하자.&lt;/li&gt;
  &lt;li&gt;다른 기획도 공부하고 있는데 이번주는 안 했던 터라, 다음주부터는 시간관리를 잘 하는 것이 매우 중요할 것 같다. 피어들과 To-do list 공유를 하지만, 코어타임에 할 것만 공유했는데 개인적으로 무엇을 해야할지 매일 To-do list를 정하고 끝내는 습관이 필요할 것 같다.&lt;/li&gt;
  &lt;li&gt;인턴 때 읽었던 논문, 그 동안 공부했던 것들 전부 다 정리하기!!&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Eunjin</name></author><category term="NAVER AI Tech Boostcamp" /><category term="NAVER AI Tech Boostcamp" /><category term="AI" /><category term="회고록" /><summary type="html">이번주에 한 일 이번주에는 Pytorch에 대한 강의를 들었다. 인턴을 하면서 Pytorch를 대충 사용할 수 있다고 생각했지만 몰랐던 부분, 잊고 있었던 부분을 리마인드 할 수 있었다. 과제 마감에만 집중을 하니 그냥 넘긴 부분도 있어서 다시 복습하고 블로그에 정리해야할 것 같다. 부스트캠프를 하느라 알고리즘, 개인공부, 블로그를 많이 못 했다. 안수빈님의 데이터 시각화 강의도 들었다. 라이엇 게임즈 유석문CTO님의 ‘개발자로 산다는것’, ‘Unit Test’ 강의를 들었다.</summary></entry><entry><title type="html">Git이란</title><link href="http://localhost:4000/git/git/" rel="alternate" type="text/html" title="Git이란" /><published>2021-08-19T00:00:00+09:00</published><updated>2021-08-19T00:00:00+09:00</updated><id>http://localhost:4000/git/git</id><content type="html" xml:base="http://localhost:4000/git/git/">&lt;p&gt;&amp;lt;현재 작성 중인 페이지입니다!!&amp;gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;git이란&quot;&gt;Git이란&lt;/h2&gt;
&lt;p&gt;Git이란 &lt;strong&gt;분산시스템을 기반으로한 형상관리도구&lt;/strong&gt;입니다.&lt;/p&gt;

&lt;p&gt;Git을 공부하다보면 처음에는 “Git을 대체 왜 사용하는가”에 대한 의문을 가질 수 있습니다. 특히, 회사에 다녀보지 않았거나 큰 프로젝트를 진행해보지 못한 경우에는 더욱 그렇게 생각하실 수 있을 것 같습니다. 하지만, 프로젝트가 극단적으로 크다고 가정했을 경우 Git이란 협업을 가능하게 해주고 버전관리를 쉽게 해주는 유용한 도구입니다. 예를 들면&lt;a href=&quot;https://github.com/torvalds/linux&quot;&gt;리눅스 프로젝트&lt;/a&gt;를 예시로 들 수 있습니다. 이런 엄청나게 큰 프로젝트를 일일히 작성하고 관리하는 것은 더욱 어려운 일입니다. 이런 문제를 해결하기 위해 나온 것이 Git이라고 생각하면 될 것 같습니다.&lt;/p&gt;

&lt;p&gt;Git을 처음 접해보는 분들께 저의 경험을 이야기해보자면, 저도 대학교 1년때 과제를 Git에 올리라는 이야기를 듣고 Git이 어떤 건지 이해를 못해서 과제 제출을 위한 명령어 순서를 외워서 올렸던 기억이 있습니다. git 명령어는 뭔지..어떤게 있는지 어려웠던 기억이 있네요. 요즘에는 Vscode, Source Tree, Gitkraken과 같이 git을 위한 좋은 gui 툴을 사용하면 되지만, 그 당시에는 지식이 부족하여 많이 헤맸습니다. (사실 1학년 지나고도 모르겠어서 git 공부만 여러 번 했던 것 같습니다…)&lt;/p&gt;

&lt;h2 id=&quot;repository&quot;&gt;Repository&lt;/h2&gt;

&lt;p&gt;이제 본격적으로 Git이 무엇인지 살펴봅시다. Git에는 &lt;strong&gt;저장소&lt;/strong&gt;라는 것이 있고, 이 저장소에는 히스토리, 소스코드, 소스코드의 브랜치, 프로그램의 여러 버전 등을 저장할 수 있습니다. Repository는 아래와 같이 2가지 종류가 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remote Repository&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;파일이나 소스를 원격 저장 공간에 저장 및 관리하는 곳으로 여러 사용자가 공유하기 위한 저장소&lt;/li&gt;
  &lt;li&gt;git server program이라고 생각&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Local Repository&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;사용자의 PC에 파일이 저장되는 개인 저장소&lt;/li&gt;
  &lt;li&gt;git client program이라고 생각&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 로컬 저장소(Local Repository)와 원격 저장소(Remote Repository)에서 소스코드 버전관리를 할 수 있기 때문에 작업하기 빠르다는 장점이 있고, 로컬 혹은 원격저장시스템에 문제가 생겨도 쉽게 대응할 수 있습니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-19-git/git-img1.png&quot; /&gt;&lt;/center&gt;

&lt;p&gt;Git을 멀리서 보면 위의 이미지와 같이 요약할 수 있습니다. 흔히들 서버라고 부르는 원격저장소를 통해 소스코드를 저장, 버전 관리 등을 하고, 만약 사용자가 소스코드나 어떤 상태의 버전을 가지고 오고 싶다고 하면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git clone&lt;/code&gt; 혹은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git pull&lt;/code&gt;이라는 명령어를 통해서 원격저장소에 있는 소스코드들을 로컬 저장소로 가지고 올 수가 있습니다 (두 명령어의 차이는 밑에서 설명할 예정입니다.). 반대로 로컬 저장소에 있는 소스코드나 파일을 원격 저장소에 저장하고 싶다면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git push&lt;/code&gt;를 통해 원격 저장소에 저장할 수 있습니다. 이렇게 로컬저장소에서 작업한 코드들을 원격 저장소에 저장할 수 있고, 다른 사람들이 작성한 코드를 원격 저장소에 저장해두면 받아올 수도 있습니다.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git clone&lt;/code&gt;과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git pull&lt;/code&gt;의 차이점에 대해 더 알아봅시다.&lt;/p&gt;

&lt;h3 id=&quot;clone&quot;&gt;clone&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git clone [URL]&lt;/code&gt;를 통해 원격 저장소에 있는 모든 내용을 복사할 수 있습니다. clone을 하게 되면 자동적으로 내 로컬저장소를 생성하고 로컬 저장소를 url의 원격저장소와 연결하게 됩니다. 여기서 주의해야할 점 중 하나는 URL이란 보통 웹사이트의 주소가 아닌 아래의 이미지와 같이 원격 저장소의 주소를 가져와야합니다. 보통 github 페이지의 웹 상단에 보이는 주소는 원격저장소를 보여주기 위한 주소이기 때문에 원격 저장소의 주소와 다릅니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-19-git/git-img2.png&quot; width=&quot;400&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;pull&quot;&gt;pull&lt;/h3&gt;

&lt;p&gt;pull이란 원격저장소에 소스코드의 최신 버전을 다운로드해서 내 로컬 저장소에다가 내용을 적용하는 것입니다.
그렇기 때문에 이미 로컬저장소가 있는 상태에서 사용합니다. 만약 로컬저장소가 없다면 아래와 같이 설정하면 됩니다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git init # 로컬 저장소 생성
git remote add origin [URL] # 로컬 저장소를 원격 저장소와 연결
git pull origin main # 원격 저장소에 있는 파일들을 가져옴
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;먼저 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git init&lt;/code&gt;을 통해 내 컴퓨터에 로컬 저장소를 만들수 있습니다. 이후, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git remote add orgin [URL]&lt;/code&gt;을 통해 origin이라는 이름을 가진 git 서버와 연결합니다. 이후 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git pull origin main&lt;/code&gt;이라는 명령어를 통해 origin 서버의 내용들을 main 브랜치(지금은 client 서버로 생각해도 됩니다.)로 가지고 옵니다. 사실 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git pull&lt;/code&gt;이라는 명령어는 자세히 보면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git fetch&lt;/code&gt;와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git merge&lt;/code&gt; 명령어를 합친 것이라고 생각하면 되는데, 이에 대해서는 나중에 다시 설명할 예정입니다.&lt;/p&gt;

&lt;h3 id=&quot;origin-main&quot;&gt;Origin, Main&lt;/h3&gt;

&lt;p&gt;명령어 예시에 origin과 main이 무엇인지 간단하게 알아봅시다.
보통 원격저장소를 생성하면 &lt;strong&gt;origin&lt;/strong&gt;이라는 별칭이 붙고, 기본적으로 생성되는 초기 브랜치의 이름은 &lt;strong&gt;main&lt;/strong&gt;으로 설정됩니다. (예전에는 초기 상태 브랜치가 master였지만 2020년 10월 이후 main으로 변경됐다고 합니다.) 브랜치라는 것은 내가 현재 작업하고 있는 공간이라고 생각하시면 됩니다.&lt;/p&gt;

&lt;h2 id=&quot;로컬-저장소에-파일-업로드하기commit&quot;&gt;로컬 저장소에 파일 업로드하기(Commit)&lt;/h2&gt;
&lt;p&gt;로컬 저장소에 내가 현재 작업하고 있는 소스 코드들을 저장을 하기 위해서는 working tree, staging area, commit이 무엇인지 알아야합니다. 아래의 이미지를 보면 파일을 올리기 위해서는 3가지 과정이 필요합니다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;내가 현재 작업하고 있는 곳(Working Tree)에서 파일들을 수정합니다.&lt;/li&gt;
  &lt;li&gt;로컬 저장소에 저장하기 위한 공간(Staging Area)에 저장합니다.&lt;/li&gt;
  &lt;li&gt;이 공간에 있는 파일들을 로컬 저장소에 올립니다. (Commit 작업)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이렇게 3가지의 과정을 통해 로컬 저장소에 파일들을 올릴 수 있습니다.&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-19-git/git-img3.png&quot; /&gt;&lt;/center&gt;

&lt;h3 id=&quot;working-tree&quot;&gt;Working Tree&lt;/h3&gt;

&lt;p&gt;Working Tree란 &lt;strong&gt;저장소의 어느 한 시점으로부터 사용자가 현재 작업하는 시점/공간&lt;/strong&gt;을 이야기합니다. 즉, 내가 어떤 버전의 프로그램의 소스코드들을 작성하고 있고, 그 때 내가 작업하는 파일 디렉토리라고 생각하시면 됩니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git status&lt;/code&gt;라는 명령어를 통해 현재 working tree의 수정된 파일들과 staging area에 있는 파일의 상태를 볼 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;staging-area&quot;&gt;Staging Area&lt;/h3&gt;

&lt;p&gt;Staging Area란 &lt;strong&gt;원격 저장소에 Commit하기 전에 Commit을 준비하는 공간&lt;/strong&gt;이고, 인덱스라고도 합니다.
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git add&lt;/code&gt; 명령어를 사용해서 원하는 파일들을 &lt;strong&gt;staging area&lt;/strong&gt;로 보낼 수 있습니다.&lt;/p&gt;

&lt;p&gt;파일 별로 추가: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git add {file_name}&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;모든 파일 추가: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git add .&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;모든 파일 add 취소: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset HEAD&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;파일별로 add 취소:  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git reset HEAD {file_name}&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;commit&quot;&gt;Commit&lt;/h3&gt;

&lt;p&gt;Commit이란 &lt;strong&gt;변경된 사항을 확정하고 저장소에 저장하는 작업&lt;/strong&gt;입니다. 각 커밋마다 알파벳, 숫자로 이루어진 40자리 고유 이름이 생성되고 이를 사용해서 이전 버전으로 확인, 복구 등의 작업을 할 수 있습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git commit&lt;/code&gt; 또는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git commit -m [message]&lt;/code&gt;라는 명령어를 통해 내가 커밋할 내용에 대한 메세지를 작성(예. file.py를 수정했습니다)하고 로컬 저장소에 저장할 수 있습니다.&lt;/p&gt;

&lt;h4 id=&quot;commit-message-작성&quot;&gt;Commit Message 작성&lt;/h4&gt;
&lt;p&gt;다른 사람과 같이 작업을 하는 경우에는 협업 효율을 위해 좋은 커밋 메세지를 적는 방법도 중요합니다. 보통 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git commit -m [message]&lt;/code&gt;를 통해서 간단하게 메세지를 적을 수도 있지만, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;git commit&lt;/code&gt; 후 더 자세한 commit message 작성할 수 있습니다.
좋은 커밋 메세지를 적는 방법은 &lt;a href=&quot;https://meetup.toast.com/posts/106&quot;&gt;이 링크&lt;/a&gt;를 통해 더욱 자세히 볼 수 있습니다.
또한, 예시로 &lt;a href=&quot;https://github.com/facebookresearch/detectron2/commit/cd60faf1427f95d357ba30365a415d0309a8618f&quot;&gt;이 링크&lt;/a&gt;를 통해 Facebook AI 팀에서는 어떤 방식으로 메세지를 올리는지 확인해볼 수 있습니다.&lt;/p&gt;

&lt;h3 id=&quot;git의-파일-관리&quot;&gt;Git의 파일 관리&lt;/h3&gt;
&lt;p&gt;로컬 저장소에서 파일 관리는 아래와 같이 3가지의 상태로 나타낼 수 있습니다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Modified: 로컬에서 작업한 후 변경된 내용&lt;/li&gt;
  &lt;li&gt;Committed: 로컬에서 작업한 후 로컬 저장소에 저장된 상태&lt;/li&gt;
  &lt;li&gt;Staged: Modified하여 곧 Commit이 될 파일들&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;head&quot;&gt;Head&lt;/h3&gt;

&lt;!-- 현재 작업중인 Branch를 가리킨다. --&gt;

&lt;h3 id=&quot;branch&quot;&gt;Branch&lt;/h3&gt;
&lt;!-- 
- 작업을 할때 다른 가지에서 새로운 가지를 치고(현재 상태를 복사) 생성한 브랜치에서 작업 후 다른 브랜치랑 Merge를 하는 방식으로 작업을 한다.
- 보통 개발 브랜치, feature 브랜치 등으로 나누어서 통합하고 메인 브랜치에 통합하는 방식으로 진행된다.

브랜치 생성: `git branch {생성할 브랜치 이름}`

브랜치 변경: `git checkout {이동할 브랜치 이름}`

로컬 저장소의 브랜치 확인:  `git branch`

원격 저장소의 브랜치 확인:  `git branch -r`

모든 브랜치 확인:  `git branch -a`

원격 저장소의 브랜치 가져오기&amp;가져온 브랜치로 브랜치 변경: `git checkout -t {원격 저장소의 브랜치}`
 --&gt;

&lt;h2 id=&quot;merge&quot;&gt;Merge&lt;/h2&gt;

&lt;h2 id=&quot;git-flow&quot;&gt;Git Flow&lt;/h2&gt;

&lt;p&gt;Git에 대해 조금 더 알아봅시다. Git을 과연 어떻게 효율적으로 사용할 수 있을까에 대한 고민을 하실 수 있을 겁니다. 만약 이게 간단한 프로젝트라면 그냥 혼자서 파일을 업로드하고 수정하면 되지만, 많은 사람이 함께 기능들을 개발하는 경우에는 브랜치를 어떻게 생성하고 개발할지에 대한 고민을 할 수 있을 겁니다. 이를 위한 Git을 잘 사용하는 전략인 Git Flow를 살펴볼 수 있습니다. Git Flow란 Git으로 협업할 때, 브랜치 전략이라고 할 수 있습니다.&lt;/p&gt;

&lt;p&gt;예시를 살펴보면 “우아한 형제들”에서 사용하는 Git Flow를 보면 이해가 되실 거라고 생각합니다.&lt;/p&gt;

&lt;p&gt;예시) &lt;a href=&quot;https://woowabros.github.io/experience/2017/10/30/baemin-mobile-git-branch-strategy.html&quot;&gt;우아한 형제들 Git Flow&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;NAVER AI Boostcamp의 이고잉님의 특강&lt;/li&gt;
  &lt;li&gt;내 머릿속과 노트&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Eunjin</name></author><category term="git" /><category term="git" /><category term="dev" /><summary type="html">&amp;lt;현재 작성 중인 페이지입니다!!&amp;gt;</summary></entry><entry><title type="html">[논문리뷰] Vision Transformer(ViT)</title><link href="http://localhost:4000/paper%20review/cv/ViT/" rel="alternate" type="text/html" title="[논문리뷰] Vision Transformer(ViT)" /><published>2021-08-17T00:00:00+09:00</published><updated>2021-08-17T00:00:00+09:00</updated><id>http://localhost:4000/paper%20review/cv/ViT</id><content type="html" xml:base="http://localhost:4000/paper%20review/cv/ViT/">&lt;p&gt;&lt;br /&gt;&lt;br /&gt;
논문: &lt;a href=&quot;https://arxiv.org/pdf/2010.11929.pdf&quot;&gt;“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;핵심-요약&quot;&gt;핵심 요약&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Image Recognition에 NLP에서 사용되던 모델 Transformer를 적용&lt;/li&gt;
  &lt;li&gt;컴퓨터비전에서 CNN의 구조를 사용한 모델 구조를 대체&lt;/li&gt;
  &lt;li&gt;Image patch를 linear embedding하여 트랜스포머와 거의 같은 구조의 모델에 학습&lt;/li&gt;
  &lt;li&gt;CNN 기반의 SOTA 모델보다 좋은 성능
    &lt;ul&gt;
      &lt;li&gt;단, 대량의 데이터셋으로 pre-trained 후 fine-tuning이 필요&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;Vision Transformer(ViT)란 자연어처리(NLP) 분야에서 사실상 메인 모델이라고 할 수 있는 트랜스포머를 Image Classification 에 적용한 모델입니다. 2021 ICLR에 구글 리서치 팀에서 발표한 논문으로,비전 분야에서도 CNN을 사용하지 않고 트랜스포머를 사용하여 좋은 성능을 낼 수 있다는 것이 핵심입니다. 컴퓨터비전에서는 보통 CNN을 기반으로 한 모델 구조를 사용하는데, 이번 논문에서는 CNN 구조를 활용하지 않아도 Image Classification에서 좋은 결과를 얻을 수 있다는 것을 보여줍니다. ViT에서는 이미지를 패치로 잘라서 Vision Transfomer 모델에 학습을 시켰고, SOTA CNN 모델과 비교하였을 때 보다 적은 리소스로 좋은 성능을 냈습니다.&lt;/p&gt;

&lt;h2 id=&quot;method&quot;&gt;Method&lt;/h2&gt;
&lt;h3 id=&quot;1-vision-transformervit&quot;&gt;1. Vision Transformer(ViT)&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/images/2021-08-17-ViT/ViT.png&quot; alt=&quot;vit&quot; /&gt; 
[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”
&lt;br /&gt;
&lt;br /&gt;
모델의 구조는 위의 이미지와 같이 트랜스포머 모델의 인코더와 거의 똑같이 디자인되어있습니다. 고정된 크기의 patch로 잘라진 이미지를 순서대로 embedding하여 인코더의 입력값으로 넣습니다. 
이미지의 차원이 $\mathbf{x} \in \mathbb{R}^{H \times W \times C}$이고, patch의 해상도가 $(P, P)$라고 하면 $\mathbf{x}_{p} \in \mathbb{R}^{N \times\left(P^{2} \cdot C\right)}$ 으로 flatten시킵니다. 여기서 트랜스포머는 인코더에서 정해진 입력의 크기를 사용하기 때문에 이를 맞춰주기 위해 입력 차원을 D 차원을 linear projection을 해줍니다. 이 linear project의 결과 값에 positional embedding을 추가해준 값이 ViT의 인코더의 입력값으로 들어가게 됩니다. 그리고 활성화 함수로는 GELU를 사용하였습니다.
&lt;!-- classification을 하기위해 &quot;classification token&quot;을 새로 추가하여 학습을 하였습니다.  --&gt;&lt;/p&gt;

&lt;p&gt;Positinal Embedding은 이미지의 공간적인 정보를 위해 1D learnable embedding 벡터를 추가하여 학습시켰습니다. 2D learnable embedding 벡터로 실험도 해보았지만, 성능이 크게 향상되지 않아서 1D로 학습했다고 되어있습니다.&lt;/p&gt;

&lt;h4 id=&quot;inductive-bias&quot;&gt;Inductive Bias&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://velog.io/@euisuk-chung/Inductive-Bias%EB%9E%80&quot;&gt;Inductive Bias&lt;/a&gt;에 대한 설명은 링크에 잘 나와있습니다.
ViT에서는 MLP 레이어에서만 Locality와 Translation Equivariance한 특징을 가지고 있고, Self-Attention Layer에서는 Global한 이미지의 feature를 학습하게 됩니다. 아마, Transformer 모델의 구조를 이해하셨다면 쉽게 이해가 되실 겁니다. 즉, 다른 이미지 패치와의 Attention을 학습하기 때문에 Global한 feature를 학습한다고 할 수 있습니다.
이렇게 학습된 임베딩 벡터는 MLP에서 Classification이 수행됩니다.
Fine-tuning시에는 다른 해상도의 이미지를 사용하는 경우, 패치의 2D 공간에 대한 정보를 가지고 있지 않기 때문에 positional embedding을 scratch부터 학습해야합나다.&lt;/p&gt;

&lt;h4 id=&quot;hybrid-architecture&quot;&gt;Hybrid Architecture&lt;/h4&gt;
&lt;p&gt;Hybrid 구조에서는 CNN에서 나온 feature map을 ViT의 입력값으로 넣어 학습시킵니다. 마찬가지로 dimension D로 linear projection이 그대로 feature map에 적용이 되고, 그 값에 positional embedding이 더해집니다.&lt;/p&gt;

&lt;h3 id=&quot;2-fine-tuning-and-higher-resolution&quot;&gt;2. Fine-tuning and Higher Resolution&lt;/h3&gt;
&lt;p&gt;대량의 데이터셋에 pre-train한 후, 작은 downstream tasks에 fine-tuning 합니다. fine-tuning시, prediction head를 제거하고 $D \times K$ feedforward layer를 0으로 초기화하여 다시 학습시킵니다. 만약 같은 patch 크기에 더 높은 해상도의 이미지로 fine-tuning을 시키는 경우, 더 긴 sequence를 사용하게 되고 정확도 향상에도 도움이 된다고 알려져있습니다.&lt;/p&gt;

&lt;h2 id=&quot;experiment&quot;&gt;Experiment&lt;/h2&gt;
&lt;p&gt;Pre-training은 아래의 세가지 데이터셋을 활용해서 학습하였고, JFT로 학습시켰을 때 성능이 제일 좋은 것을 확인해볼 수 있습니다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ImageNet&lt;/li&gt;
  &lt;li&gt;ImageNet-21K&lt;/li&gt;
  &lt;li&gt;JFT-300M&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;CNN 계열에서 SOTA 모델이라고 할 수 있는 BiT와 비교했을 때 결과는 아래와 같다. JFT로 pre-train되고 parameter의 개수가 가장 많은 모델이 성능이 제일 높게 나오는 것을 확인할 수 있습니다. 그 외에 다른 hyparameter와 환경 세팅은 논문에 나와있으니 참고하시면 될 것 같습니다. 
&lt;br /&gt;&lt;/p&gt;

&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-17-ViT/ViT-exp3.png&quot; width=&quot;500&quot; /&gt;&lt;/center&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-17-ViT/ViT-exp1.png&quot; width=&quot;700&quot; /&gt;&lt;/center&gt;
&lt;p&gt;[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”&lt;/p&gt;

&lt;p&gt;아래는 입력 이미지와 ViT 모델을 통해 Attention이 학습된 결과 이미지 입니다.&lt;/p&gt;
&lt;center&gt;&lt;img src=&quot;/assets/images/2021-08-17-ViT/ViT-exp2.png&quot; width=&quot;250&quot; /&gt;&lt;/center&gt;
&lt;p&gt;[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;논문에서는 이미지를 NLP처럼 sequence로 프로세싱하여 트랜스포머 모델에 학습시켜 CNN 계열의 SOTA 모델만큼의 성능을 냈고, 상대적으로 pre-train 비용이 적고, scalable하다는 장점이 있다고 합니다. 
앞으로 도전해야할 2가지는&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ViT를 detection과 segmentation과 같은 다른 비전 분야에 ViT 모델에 적용시키는 것&lt;/li&gt;
  &lt;li&gt;self-supervised pre-training 방법을 계속 시도하는 것
이라고 합니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;제가 알고 있기로는 ECCV 2020에 페이스북 AI에서 트랜스포머 모델을 Detection에 적용한 연구라는 모델에 대한 논문을 냈습니다.  마찬가지로 다른 CNN 계열의 SOTA Detection 모델이 이상의 성능을 낸 걸로 알고 있습니다. 나중에 &lt;a href=&quot;https://arxiv.org/pdf/2005.12872.pdf&quot;&gt;이 논문&lt;/a&gt;도 리뷰할 예정이니 관심이 있으신 분들은 읽어보시면 좋을 것 같습니다.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/pdf/2010.11929.pdf&quot;&gt;“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;
틀린 부분이나 부족한 점이 있다면 알려주시면 감사하겠습니다:)&lt;/p&gt;</content><author><name>Eunjin</name></author><category term="Paper Review" /><category term="CV" /><category term="CV" /><category term="Image Classification" /><category term="Paper Review" /><category term="DL" /><summary type="html">논문: “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</summary></entry></feed>