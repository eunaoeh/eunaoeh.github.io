<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.24.0 by Michael Rose
  Copyright 2013-2020 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="ko" class="no-js">
  <head>
    <meta charset="utf-8">

<!-- begin _includes/seo.html --><title>[논문리뷰] Vision Transformer(ViT) - Eunaoeh’s Dev Blog</title>
<meta name="description" content="논문: “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”">


  <meta name="author" content="Eunjin">
  
  <meta property="article:author" content="Eunjin">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="ko">
<meta property="og:site_name" content="Eunaoeh's Dev Blog">
<meta property="og:title" content="[논문리뷰] Vision Transformer(ViT)">
<meta property="og:url" content="http://localhost:4000/paper%20review/cv/ViT/">


  <meta property="og:description" content="논문: “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”">







  <meta property="article:published_time" content="2021-08-17T00:00:00+09:00">





  

  


<link rel="canonical" href="http://localhost:4000/paper%20review/cv/ViT/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "Eunjin",
      "url": "http://localhost:4000/"
    
  }
</script>







<!-- end _includes/seo.html -->



  <link href="/feed.xml" type="application/atom+xml" rel="alternate" title="Eunaoeh's Dev Blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/assets/css/main.css">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
<noscript><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"></noscript>



    <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->

<!-- end custom head snippets -->

    
      <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX", "output/HTML-CSS"],
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
      processEscapes: true
    },
    "HTML-CSS": { availableFonts: ["TeX"] }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
	  alert("Math Processing Error: "+message[1]);
	});
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
    
  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
        <a class="site-title" href="/">
          Eunaoeh's Dev Blog
          
        </a>
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/about/">About</a>
            </li><li class="masthead__menu-item">
              <a href="/">Home</a>
            </li><li class="masthead__menu-item">
              <a href="/categories/">Categories</a>
            </li><li class="masthead__menu-item">
              <a href="/tags/">Tags</a>
            </li></ul>
        
        <button class="search__toggle" type="button">
          <span class="visually-hidden">Toggle search</span>
          <i class="fas fa-search"></i>
        </button>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">토글 메뉴</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      



<div id="main" role="main">
  
  <div class="sidebar sticky">
  


<div itemscope itemtype="https://schema.org/Person" class="h-card">

  
    <div class="author__avatar">
      <a href="http://localhost:4000/">
        <img src="/assets/images/portfolio.jpeg" alt="Eunjin" itemprop="image" class="u-photo">
      </a>
    </div>
  

  <div class="author__content">
    <h3 class="author__name p-name" itemprop="name">
      <a class="u-url" rel="me" href="http://localhost:4000/" itemprop="url">Eunjin</a>
    </h3>
    
      <div class="author__bio p-note" itemprop="description">
        <p>ᕙ(^▿^-ᕙ)</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">팔로우</button>
    <ul class="author__urls social-icons">
      
        <li itemprop="homeLocation" itemscope itemtype="https://schema.org/Place">
          <i class="fas fa-fw fa-map-marker-alt" aria-hidden="true"></i> <span itemprop="name" class="p-locality">Somewhere in Korea</span>
        </li>
      

      
        
          
            <li><a href="eunjinhh131@gmail.com" rel="nofollow noopener noreferrer me"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i><span class="label">Email</span></a></li>
          
        
          
        
          
        
          
        
          
            <li><a href="https://github.com/eunaoeh" rel="nofollow noopener noreferrer me"><i class="fab fa-fw fa-github" aria-hidden="true"></i><span class="label">GitHub</span></a></li>
          
        
          
        
      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer me">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>
  
  </div>



  <article class="page h-entry" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="[논문리뷰] Vision Transformer(ViT)">
    <meta itemprop="description" content="논문: “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”">
    <meta itemprop="datePublished" content="2021-08-17T00:00:00+09:00">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 id="page-title" class="page__title p-name" itemprop="headline">
            <a href="http://localhost:4000/paper%20review/cv/ViT/" class="u-url" itemprop="url">[논문리뷰] Vision Transformer(ViT)
</a>
          </h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          3 분 소요
        
      </span>
    
  </p>


        </header>
      

      <section class="page__content e-content" itemprop="text">
        
          <aside class="sidebar__right sticky">
            <nav class="toc">
              <header><h4 class="nav__title"><i class="fas fa-file-alt"></i> On This Page</h4></header>
              <ul class="toc__menu"><li><a href="#핵심-요약">핵심 요약</a></li><li><a href="#abstract">Abstract</a></li><li><a href="#method">Method</a><ul><li><a href="#1-vision-transformervit">1. Vision Transformer(ViT)</a><ul><li><a href="#inductive-bias">Inductive Bias</a></li><li><a href="#hybrid-architecture">Hybrid Architecture</a></li></ul></li><li><a href="#2-fine-tuning-and-higher-resolution">2. Fine-tuning and Higher Resolution</a></li></ul></li><li><a href="#experiment">Experiment</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#reference">Reference</a></li></ul>

            </nav>
          </aside>
        
        <p><br /><br />
논문: <a href="https://arxiv.org/pdf/2010.11929.pdf">“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</a></p>

<h2 id="핵심-요약">핵심 요약</h2>
<ul>
  <li>Image Recognition에 NLP에서 사용되던 모델 Transformer를 적용</li>
  <li>컴퓨터비전에서 CNN의 구조를 사용한 모델 구조를 대체</li>
  <li>Image patch를 linear embedding하여 트랜스포머와 거의 같은 구조의 모델에 학습</li>
  <li>CNN 기반의 SOTA 모델보다 좋은 성능
    <ul>
      <li>단, 대량의 데이터셋으로 pre-trained 후 fine-tuning이 필요</li>
    </ul>
  </li>
</ul>

<h2 id="abstract">Abstract</h2>
<p>Vision Transformer(ViT)란 자연어처리(NLP) 분야에서 사실상 메인 모델이라고 할 수 있는 트랜스포머를 Image Classification 에 적용한 모델입니다. 2021 ICLR에 구글 리서치 팀에서 발표한 논문으로,비전 분야에서도 CNN을 사용하지 않고 트랜스포머를 사용하여 좋은 성능을 낼 수 있다는 것이 핵심입니다. 컴퓨터비전에서는 보통 CNN을 기반으로 한 모델 구조를 사용하는데, 이번 논문에서는 CNN 구조를 활용하지 않아도 Image Classification에서 좋은 결과를 얻을 수 있다는 것을 보여줍니다. ViT에서는 이미지를 패치로 잘라서 Vision Transfomer 모델에 학습을 시켰고, SOTA CNN 모델과 비교하였을 때 보다 적은 리소스로 좋은 성능을 냈습니다.</p>

<h2 id="method">Method</h2>
<h3 id="1-vision-transformervit">1. Vision Transformer(ViT)</h3>
<p><img src="/assets/images/2021-08-17-ViT/ViT.png" alt="vit" /> 
[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”
<br />
<br />
모델의 구조는 위의 이미지와 같이 트랜스포머 모델의 인코더와 거의 똑같이 디자인되어있습니다. 고정된 크기의 patch로 잘라진 이미지를 순서대로 embedding하여 인코더의 입력값으로 넣습니다. 
이미지의 차원이 $\mathbf{x} \in \mathbb{R}^{H \times W \times C}$이고, patch의 해상도가 $(P, P)$라고 하면 $\mathbf{x}_{p} \in \mathbb{R}^{N \times\left(P^{2} \cdot C\right)}$ 으로 flatten시킵니다. 여기서 트랜스포머는 인코더에서 정해진 입력의 크기를 사용하기 때문에 이를 맞춰주기 위해 입력 차원을 D 차원을 linear projection을 해줍니다. 이 linear project의 결과 값에 positional embedding을 추가해준 값이 ViT의 인코더의 입력값으로 들어가게 됩니다. 그리고 활성화 함수로는 GELU를 사용하였습니다.
<!-- classification을 하기위해 "classification token"을 새로 추가하여 학습을 하였습니다.  --></p>

<p>Positinal Embedding은 이미지의 공간적인 정보를 위해 1D learnable embedding 벡터를 추가하여 학습시켰습니다. 2D learnable embedding 벡터로 실험도 해보았지만, 성능이 크게 향상되지 않아서 1D로 학습했다고 되어있습니다.</p>

<h4 id="inductive-bias">Inductive Bias</h4>
<p><a href="https://velog.io/@euisuk-chung/Inductive-Bias%EB%9E%80">Inductive Bias</a>에 대한 설명은 링크에 잘 나와있습니다.
ViT에서는 MLP 레이어에서만 Locality와 Translation Equivariance한 특징을 가지고 있고, Self-Attention Layer에서는 Global한 이미지의 feature를 학습하게 됩니다. 아마, Transformer 모델의 구조를 이해하셨다면 쉽게 이해가 되실 겁니다. 즉, 다른 이미지 패치와의 Attention을 학습하기 때문에 Global한 feature를 학습한다고 할 수 있습니다.
이렇게 학습된 임베딩 벡터는 MLP에서 Classification이 수행됩니다.
Fine-tuning시에는 다른 해상도의 이미지를 사용하는 경우, 패치의 2D 공간에 대한 정보를 가지고 있지 않기 때문에 positional embedding을 scratch부터 학습해야합나다.</p>

<h4 id="hybrid-architecture">Hybrid Architecture</h4>
<p>Hybrid 구조에서는 CNN에서 나온 feature map을 ViT의 입력값으로 넣어 학습시킵니다. 마찬가지로 dimension D로 linear projection이 그대로 feature map에 적용이 되고, 그 값에 positional embedding이 더해집니다.</p>

<h3 id="2-fine-tuning-and-higher-resolution">2. Fine-tuning and Higher Resolution</h3>
<p>대량의 데이터셋에 pre-train한 후, 작은 downstream tasks에 fine-tuning 합니다. fine-tuning시, prediction head를 제거하고 $D \times K$ feedforward layer를 0으로 초기화하여 다시 학습시킵니다. 만약 같은 patch 크기에 더 높은 해상도의 이미지로 fine-tuning을 시키는 경우, 더 긴 sequence를 사용하게 되고 정확도 향상에도 도움이 된다고 알려져있습니다.</p>

<h2 id="experiment">Experiment</h2>
<p>Pre-training은 아래의 세가지 데이터셋을 활용해서 학습하였고, JFT로 학습시켰을 때 성능이 제일 좋은 것을 확인해볼 수 있습니다.</p>
<ul>
  <li>ImageNet</li>
  <li>ImageNet-21K</li>
  <li>JFT-300M</li>
</ul>

<p>CNN 계열에서 SOTA 모델이라고 할 수 있는 BiT와 비교했을 때 결과는 아래와 같다. JFT로 pre-train되고 parameter의 개수가 가장 많은 모델이 성능이 제일 높게 나오는 것을 확인할 수 있습니다. 그 외에 다른 hyparameter와 환경 세팅은 논문에 나와있으니 참고하시면 될 것 같습니다. 
<br /></p>

<center><img src="/assets/images/2021-08-17-ViT/ViT-exp3.png" width="500" /></center>
<center><img src="/assets/images/2021-08-17-ViT/ViT-exp1.png" width="700" /></center>
<p>[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</p>

<p>아래는 입력 이미지와 ViT 모델을 통해 Attention이 학습된 결과 이미지 입니다.</p>
<center><img src="/assets/images/2021-08-17-ViT/ViT-exp2.png" width="250" /></center>
<p>[출처] “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</p>

<h2 id="conclusion">Conclusion</h2>

<p>논문에서는 이미지를 NLP처럼 sequence로 프로세싱하여 트랜스포머 모델에 학습시켜 CNN 계열의 SOTA 모델만큼의 성능을 냈고, 상대적으로 pre-train 비용이 적고, scalable하다는 장점이 있다고 합니다. 
앞으로 도전해야할 2가지는</p>
<ul>
  <li>ViT를 detection과 segmentation과 같은 다른 비전 분야에 ViT 모델에 적용시키는 것</li>
  <li>self-supervised pre-training 방법을 계속 시도하는 것
이라고 합니다.</li>
</ul>

<p>제가 알고 있기로는 ECCV 2020에 페이스북 AI에서 트랜스포머 모델을 Detection에 적용한 연구라는 모델에 대한 논문을 냈습니다.  마찬가지로 다른 CNN 계열의 SOTA Detection 모델이 이상의 성능을 낸 걸로 알고 있습니다. 나중에 <a href="https://arxiv.org/pdf/2005.12872.pdf">이 논문</a>도 리뷰할 예정이니 관심이 있으신 분들은 읽어보시면 좋을 것 같습니다.</p>

<h2 id="reference">Reference</h2>
<ul>
  <li><a href="https://arxiv.org/pdf/2010.11929.pdf">“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”</a></li>
</ul>

<p><br /><br />
틀린 부분이나 부족한 점이 있다면 알려주시면 감사하겠습니다:)</p>

        
      </section>

      <footer class="page__meta">
        
        
  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> 태그: </strong>
    <span itemprop="keywords">
    
      <a href="/tags/#cv" class="page__taxonomy-item p-category" rel="tag">CV</a><span class="sep">, </span>
    
      <a href="/tags/#dl" class="page__taxonomy-item p-category" rel="tag">DL</a><span class="sep">, </span>
    
      <a href="/tags/#image-classification" class="page__taxonomy-item p-category" rel="tag">Image Classification</a><span class="sep">, </span>
    
      <a href="/tags/#paper-review" class="page__taxonomy-item p-category" rel="tag">Paper Review</a>
    
    </span>
  </p>




  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> 카테고리: </strong>
    <span itemprop="keywords">
    
      <a href="/categories/#cv" class="page__taxonomy-item p-category" rel="tag">CV</a><span class="sep">, </span>
    
      <a href="/categories/#paper-review" class="page__taxonomy-item p-category" rel="tag">Paper Review</a>
    
    </span>
  </p>


        

  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> 업데이트:</strong> <time class="dt-published" datetime="2021-08-17T00:00:00+09:00">August 17, 2021</time></p>

      </footer>

      

      
  <nav class="pagination">
    
      <a href="#" class="pagination--pager disabled">이전</a>
    
    
      <a href="/git/git/" class="pagination--pager" title="Git이란
">다음</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>
    </div>

    
      <div class="search-content">
        <div class="search-content__inner-wrap"><form class="search-content__form" onkeydown="return event.key != 'Enter';" role="search">
    <label class="sr-only" for="search">
      Enter your search term...
    </label>
    <input type="search" id="search" class="search-input" tabindex="-1" placeholder="검색어를 입력하세요..." />
  </form>
  <div id="results" class="results"></div></div>

      </div>
    

    <div id="footer" class="page__footer">
      <footer>
        <!-- start custom footer snippets -->

<!-- end custom footer snippets -->
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>팔로우:</strong></li>
    

    
      
        
      
        
      
        
      
        
      
        
      
        
      
    

    
      <li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> 피드</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 Eunjin. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    
  <script src="/assets/js/main.min.js"></script>




<script src="/assets/js/lunr/lunr.min.js"></script>
<script src="/assets/js/lunr/lunr-store.js"></script>
<script src="/assets/js/lunr/lunr-en.js"></script>







  </body>
</html>
